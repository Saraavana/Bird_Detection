{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "super-participant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start testing for dataset {}.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import importlib\n",
    "import gc\n",
    "import shutil\n",
    "\n",
    "from utils.nontf_util import *\n",
    "from utils.tf_util import *\n",
    "import dataset_loader\n",
    "\n",
    "\n",
    "# patch tf1 into `utils.ops`\n",
    "utils_ops.tf = tf.compat.v1\n",
    "\n",
    "# Patch the location of gfile\n",
    "tf.gfile = tf.io.gfile\n",
    "\n",
    "# os.chdir(os.path.split(__file__)[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-prompt",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.json\") as config_file:\n",
    "    config = json.load(config_file)\n",
    "    for model_dict in config['object_detectors']:\n",
    "        if not model_dict['active']:\n",
    "            continue\n",
    "        print(\"Model dict {}\".format(model_dict['name']))\n",
    "        detection_model = load_model(model_dict['name'])\n",
    "        print(\"Model {} loaded, start testing.\".format(model_dict['abr']))\n",
    "        for dataset in config['datasets']:\n",
    "            if not dataset['active']:\n",
    "                continue\n",
    "            dataset_path = os.path.normpath(dataset['path'])\n",
    "            out_dir = os.path.join(os.path.join(\n",
    "                os.path.normpath(config['output_dir']),\n",
    "                model_dict['abr']))\n",
    "            if not os.path.exists(out_dir):\n",
    "                os.makedirs(out_dir)\n",
    "\n",
    "            file_name = dataset['short_name'] + \".json\"\n",
    "            out_path = os.path.join(out_dir, file_name)\n",
    "            if not sys.path[0] == dataset_path:\n",
    "                sys.path.insert(0, dataset_path)\n",
    "\n",
    "            print(sys.path)\n",
    "            print(out_path)\n",
    "            \n",
    "            dataloader = load_pascal_voc(dataset_path,dataset,model_dict)\n",
    "            cur_dataset = dataloader['dataset']\n",
    "            \n",
    "            print(\"Start testing for dataset {}.\".format(dataset['short_name']))\n",
    "            dataset_length = len(cur_dataset['images'])\n",
    "            print()\n",
    "            progress, cur_dataset = checkprogress(out_path, cur_dataset)\n",
    "            for i, image in enumerate(cur_dataset['images']):\n",
    "                print_progress_bar(i + 1, dataset_length, prefix=\"{}/{}\".format(i + 1, dataset_length))\n",
    "                print(\"The progress is is {}\".format(progress))\n",
    "                if progress > i:\n",
    "                    continue\n",
    "                abspath = os.path.join(dataset_path, image['path'])\n",
    "                \n",
    "#                 print(\"The absolute path is {}\".format(abspath))\n",
    "        \n",
    "#                 output = run_inference(detection_model, abspath)\n",
    "#                 fasd = output['detection_boxes'][0][0]\n",
    "#                 afdsfs = output['detection_boxes'][0][1] \n",
    "#                 print(\"fasdfsd is {}\".format(fasd))\n",
    "#                 print(\"fds is {}\".format(afdsfs))\n",
    "                \n",
    "#                 print(\"Image width is {}\".format(float(image['width'])))\n",
    "                \n",
    "#                 widdsh = fasd * float(image['width'])\n",
    "#                 heighsdt = afdsfs * float(image['height'])\n",
    "                \n",
    "#                 print(\"Width is {}\".format(widdsh))\n",
    "#                 print(\"Height is {}\".format(heighsdt))\n",
    "            \n",
    "#                 image['output'] = output_to_abs(image, output)\n",
    "#                 print(\"=============\")\n",
    "#                 print(image['output'])\n",
    "                \n",
    "                try:\n",
    "                    print(\"Try block--=====\")\n",
    "                    output = run_inference(detection_model, abspath)\n",
    "                    image['output'] = output_to_abs(image, output)\n",
    "                    print(\"=============\")\n",
    "                    print(image['output'])\n",
    "                except:\n",
    "                    print(\"The exception is {}\".format(e))\n",
    "                    print(\"Problem with image_data {} from dataset {}\".format(image['path'], dataset['short_name']))\n",
    "                    \n",
    "                dataset['progress'] = [i + 1, dataset_length]\n",
    "                dump_output(config['output_dir'], model_dict, dataset, cur_dataset)\n",
    "            del cur_dataset\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "        del detection_model\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-ethernet",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_annotations = os.path.join(dataset_path,\"trainval/Annotations\")\n",
    "print(len(os.listdir(trainval_annotations)))\n",
    "trainval_images = os.path.join(dataset_path,\"trainval/JPEGImages\")\n",
    "print(len(os.listdir(trainval_images)))\n",
    "images = os.path.join(dataset_path,\"Annotations\")\n",
    "annotations = os.path.join(dataset_path,\"JPEGImages\")\n",
    "print(len(os.listdir(images)))\n",
    "print(len(os.listdir(annotations)))\n",
    "print(dataset_path)\n",
    "print(len(os.listdir(\"/Volumes/My-Passport/Dataset/VOCdevkit/VOC2012/Annotations\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-frontier",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_path)\n",
    "trainval_jpeg = os.path.join(dataset_path,\"trainval/JPEGImages\")\n",
    "trainval_annotations = os.path.join(dataset_path,\"trainval/Annotations\")\n",
    "\n",
    "trainval_data = []\n",
    "with open(trainval_path) as f:\n",
    "    trainval_data = [line.split(None, 1)[0] for line in f]\n",
    "\n",
    "if not os.path.exists(trainval_jpeg) and not os.path.exists(trainval_annotations):\n",
    "    os.makedirs(trainval_jpeg)\n",
    "    os.makedirs(trainval_annotations)\n",
    "    \n",
    "if len(os.listdir(trainval_jpeg)) == 0 and len(os.listdir(trainval_annotations)) == 0:\n",
    "    jpegs = os.path.join(dataset_path,\"JPEGImages\")\n",
    "    annotations = os.path.join(dataset_path,\"Annotations\")\n",
    "    trainval_path = os.path.join(dataset_path,\"ImageSets/Layout/trainval.txt\")\n",
    "    img_annotations = os.listdir(annotations)\n",
    "    \n",
    "    for i,each in enumerate(os.listdir(jpegs)):\n",
    "        print(i)\n",
    "        filename_no_ext = \".\".join(each.split(\".\")[:-1])\n",
    "        for item in trainval_data:\n",
    "            if item == filename_no_ext:\n",
    "                src_jpeg_path = os.path.join(jpegs,each)\n",
    "                src_annotation_path = os.path.join(annotations,img_annotations[i])\n",
    "                dst_jpeg_path = os.path.join(trainval_jpeg,each)\n",
    "                dst_annotation_path = os.path.join(trainval_annotations,img_annotations[i])\n",
    "                \n",
    "                shutil.copyfile(src_jpeg_path, dst_jpeg_path)\n",
    "                shutil.copyfile(src_annotation_path, dst_annotation_path)\n",
    "                print(item)\n",
    "        \n",
    "print(len(trainval_data))\n",
    "print(\"Training Jpeg\")\n",
    "print(len(os.listdir(trainval_jpeg)))\n",
    "print(\"Training Annotations\")\n",
    "print(len(os.listdir(trainval_annotations)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-diving",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "data_set_path = \"/Volumes/My-Passport/Dataset/CUB_200_2011/CUB_200_2011\"\n",
    "images_text_path = os.path.join(data_set_path,\"images.txt\")\n",
    "\n",
    "data = {}\n",
    "\n",
    "dataset_obj = {}\n",
    "dataset_obj['initialized'] = True\n",
    "dataset_obj['classes'] = [\"person\", \"bird\", \"cat\", \"cow\", \"dog\", \"horse\", \"sheep\", \"aeroplane\", \"bicycle\", \"boat\", \"bus\", \"car\", \"motorbike\", \"train\", \"bottle\", \"chair\", \"dining table\", \"potted plant\", \"sofa\", \"tv/monitor\"]\n",
    "\n",
    "images = []\n",
    "\n",
    "bounding_box_path = os.path.join(data_set_path,\"bounding_boxes.txt\")\n",
    "with open(bounding_box_path) as bb_path:\n",
    "    bb_lines = bb_path.readlines()\n",
    "    bb_columns = []\n",
    "\n",
    "    for bb_line in bb_lines:\n",
    "        bb_line = bb_line.strip()\n",
    "        bb_array = [bb_item.strip() for bb_item in bb_line.split(' ')]\n",
    "        bb_columns.append(bb_array)\n",
    "    \n",
    "\n",
    "with open(images_text_path) as f:\n",
    "    lines = f.readlines()\n",
    "    columns = [] # To store column names\n",
    "\n",
    "    i = 1\n",
    "    for line in lines:\n",
    "        line = line.strip() # remove leading/trailing white spaces\n",
    "        image_list_array = [item.strip() for item in line.split(' ')]\n",
    "        columns.append(image_list_array)\n",
    "    \n",
    "    for index,item in enumerate(columns):\n",
    "        coco_image_path = item[1]\n",
    "        image_obj = {}\n",
    "        image_obj['path'] = \"images/\"+coco_image_path\n",
    "        \n",
    "        image = Image.open(os.path.join(data_set_path,image_obj['path']))\n",
    "        width, height = image.size\n",
    "        image_obj['width'] = float(width)\n",
    "        image_obj['height'] = float(width)\n",
    "\n",
    "        \n",
    "        bounding_boxes = []\n",
    "        if item[0] == bb_columns[index][0]:\n",
    "            bounding_box_obj = {}\n",
    "            bounding_box_obj['x'] = bb_columns[index][1]\n",
    "            bounding_box_obj['y'] = bb_columns[index][2]\n",
    "            bounding_box_obj['width'] = bb_columns[index][3]\n",
    "            bounding_box_obj['height'] = bb_columns[index][4]\n",
    "            bounding_boxes.append(bounding_box_obj)\n",
    "        \n",
    "        image_obj['bounding_boxes'] = bounding_boxes\n",
    "        images.append(image_obj)\n",
    "    \n",
    "\n",
    "dataset_obj['images'] = images\n",
    "data['dataset'] = dataset_obj\n",
    "\n",
    "print(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "determined-novel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dict faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28\n",
      "/Users/saravana/.keras/datasets/faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28/saved_model\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "Model faster_rcnn loaded, start testing.\n",
      "['/Volumes/My-Passport/Dataset/CUB_200_2011/CUB_200_2011', '/Users/saravana/.pyenv/versions/3.6.5/lib/python36.zip', '/Users/saravana/.pyenv/versions/3.6.5/lib/python3.6', '/Users/saravana/.pyenv/versions/3.6.5/lib/python3.6/lib-dynload', '', '/Users/saravana/.pyenv/versions/3.6.5/lib/python3.6/site-packages', '/Users/saravana/.pyenv/versions/3.6.5/lib/python3.6/site-packages/IPython/extensions', '/Users/saravana/.ipython']\n",
      "/Users/saravana/Documents/Work/Projects/Bird_Detection/_bird_detector_output/faster_rcnn/CalTechCUB.json\n",
      "Start testing for dataset CalTechCUB.\n",
      "\n",
      "The progress is is 6█------------------------------------------------------------------------------------| 16.7% \n",
      "The progress is is 6██████████████████-------------------------------------------------------------------| 33.3% \n",
      "The progress is is 6███████████████████████████████████--------------------------------------------------| 50.0% \n",
      "The progress is is 6███████████████████████████████████████████████████----------------------------------| 66.7% \n",
      "The progress is is 6████████████████████████████████████████████████████████████████████-----------------| 83.3% \n",
      "6/6 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "The progress is is 6\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "from utils.nontf_util import *\n",
    "\n",
    "with open(\"config.json\") as config_file:\n",
    "    config = json.load(config_file)\n",
    "    for model_dict in config['object_detectors']:\n",
    "        if not model_dict['active']:\n",
    "            continue\n",
    "        print(\"Model dict {}\".format(model_dict['name']))\n",
    "        detection_model = load_model(model_dict['name'])\n",
    "        print(\"Model {} loaded, start testing.\".format(model_dict['abr']))\n",
    "        for dataset in config['datasets']:\n",
    "            if not dataset['active']:\n",
    "                continue\n",
    "            dataset_path = os.path.normpath(dataset['path'])\n",
    "            out_dir = os.path.join(os.path.join(\n",
    "                os.path.normpath(config['output_dir']),\n",
    "                model_dict['abr']))\n",
    "            if not os.path.exists(out_dir):\n",
    "                os.makedirs(out_dir)\n",
    "\n",
    "            file_name = dataset['short_name'] + \".json\"\n",
    "            out_path = os.path.join(out_dir, file_name)\n",
    "            if not sys.path[0] == dataset_path:\n",
    "                sys.path.insert(0, dataset_path)\n",
    "\n",
    "            print(sys.path)\n",
    "            print(out_path)\n",
    "            \n",
    "            dataloader = load_caltech_cub(dataset_path,dataset,model_dict)\n",
    "            cur_dataset = dataloader['dataset']\n",
    "            \n",
    "            print(\"Start testing for dataset {}.\".format(dataset['short_name']))\n",
    "            dataset_length = len(cur_dataset['images'])\n",
    "            print()\n",
    "            progress, cur_dataset = checkprogress(out_path, cur_dataset)\n",
    "            for i, image in enumerate(cur_dataset['images']):\n",
    "                print_progress_bar(i + 1, dataset_length, prefix=\"{}/{}\".format(i + 1, dataset_length))\n",
    "                print(\"The progress is is {}\".format(progress))\n",
    "                if progress > i:\n",
    "                    continue\n",
    "                abspath = os.path.join(dataset_path, image['path'])\n",
    "                                \n",
    "                try:\n",
    "                    output = run_inference(detection_model, abspath)\n",
    "                    image['output'] = output_to_abs(image, output)\n",
    "                    show_inference(detection_model, abspath)\n",
    "                except:\n",
    "                    print(\"The exception is {}\".format(e))\n",
    "                    print(\"Problem with image_data {} from dataset {}\".format(image['path'], dataset['short_name']))\n",
    "                    \n",
    "                dataset['progress'] = [i + 1, dataset_length]\n",
    "                dump_output(config['output_dir'], model_dict, dataset, cur_dataset)\n",
    "            del cur_dataset\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "        del detection_model\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-palmer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
