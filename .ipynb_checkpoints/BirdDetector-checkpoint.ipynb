{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "super-participant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start testing for dataset {}.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import importlib\n",
    "import gc\n",
    "import shutil\n",
    "\n",
    "from utils.nontf_util import *\n",
    "from utils.tf_util import *\n",
    "import dataset_loader\n",
    "\n",
    "\n",
    "# patch tf1 into `utils.ops`\n",
    "utils_ops.tf = tf.compat.v1\n",
    "\n",
    "# Patch the location of gfile\n",
    "tf.gfile = tf.io.gfile\n",
    "\n",
    "# os.chdir(os.path.split(__file__)[0])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "# matplotlib.use(\"TkAgg\")\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "naked-prompt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dict faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28\n",
      "/Users/saravana/.keras/datasets/faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28/saved_model\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "Model faster_rcnn loaded, start testing.\n",
      "['/Volumes/My-Passport/Dataset/CUB_200_2011/CUB_200_2011', '/Users/saravana/.pyenv/versions/3.6.5/lib/python36.zip', '/Users/saravana/.pyenv/versions/3.6.5/lib/python3.6', '/Users/saravana/.pyenv/versions/3.6.5/lib/python3.6/lib-dynload', '', '/Users/saravana/.pyenv/versions/3.6.5/lib/python3.6/site-packages', '/Users/saravana/.pyenv/versions/3.6.5/lib/python3.6/site-packages/IPython/extensions', '/Users/saravana/.ipython']\n",
      "/Users/saravana/Documents/Work/Projects/Bird_Detection/_bird_detector_output/faster_rcnn/CalTechCUB.json\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Volumes/My-Passport/Dataset/CUB_200_2011/CUB_200_2011/bounding_boxes.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9324f6616c76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#             dataloader = load_pascal_voc(dataset_path,dataset,model_dict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_caltech_cub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mcur_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Projects/Bird_Detection/utils/nontf_util.py\u001b[0m in \u001b[0;36mload_caltech_cub\u001b[0;34m(dataset_path, dataset_meta, model)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0mbounding_box_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"bounding_boxes.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbounding_box_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbb_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0mbb_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbb_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mbb_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Volumes/My-Passport/Dataset/CUB_200_2011/CUB_200_2011/bounding_boxes.txt'"
     ]
    }
   ],
   "source": [
    "with open(\"config.json\") as config_file:\n",
    "    config = json.load(config_file)\n",
    "    for model_dict in config['object_detectors']:\n",
    "        if not model_dict['active']:\n",
    "            continue\n",
    "        print(\"Model dict {}\".format(model_dict['name']))\n",
    "        detection_model = load_model(model_dict['name'])\n",
    "        print(\"Model {} loaded, start testing.\".format(model_dict['abr']))\n",
    "        for dataset in config['datasets']:\n",
    "            if not dataset['active']:\n",
    "                continue\n",
    "            dataset_path = os.path.normpath(dataset['path'])\n",
    "            out_dir = os.path.join(os.path.join(\n",
    "                os.path.normpath(config['output_dir']),\n",
    "                model_dict['abr']))\n",
    "            if not os.path.exists(out_dir):\n",
    "                os.makedirs(out_dir)\n",
    "\n",
    "            file_name = dataset['short_name'] + \".json\"\n",
    "            out_path = os.path.join(out_dir, file_name)\n",
    "            if not sys.path[0] == dataset_path:\n",
    "                sys.path.insert(0, dataset_path)\n",
    "\n",
    "            print(sys.path)\n",
    "            print(out_path)\n",
    "            \n",
    "#             dataloader = load_pascal_voc(dataset_path,dataset,model_dict)\n",
    "            dataloader = load_caltech_cub(dataset_path,dataset,model_dict)\n",
    "            cur_dataset = dataloader['dataset']\n",
    "            \n",
    "            print(\"Start testing for dataset {}.\".format(dataset['short_name']))\n",
    "            dataset_length = len(cur_dataset['images'])\n",
    "            progress, cur_dataset = checkprogress(out_path, cur_dataset)\n",
    "            for i, image in enumerate(cur_dataset['images']):\n",
    "                print_progress_bar(i + 1, dataset_length, prefix=\"{}/{}\".format(i + 1, dataset_length))\n",
    "                print(\"The progress is {}\".format(progress))\n",
    "                if progress > i:\n",
    "                    continue\n",
    "                abspath = os.path.join(dataset_path, image['path'])\n",
    "                \n",
    "                print(\"The absolute path is {}\".format(abspath))\n",
    "                \n",
    "                try:\n",
    "                    print(\"Try block--=====\")\n",
    "                    output = run_inference(detection_model, abspath)\n",
    "                    image['output'] = output_to_abs(image, output)\n",
    "                    print(\"=============\")\n",
    "                    print(image['output'])\n",
    "                    show_bb_box(output, abspath)\n",
    "#                     show_inference(detection_model, abspath)\n",
    "                except:\n",
    "                    print(\"The exception is {}\".format(e))\n",
    "                    print(\"Problem with image_data {} from dataset {}\".format(image['path'], dataset['short_name']))\n",
    "                    \n",
    "                dataset['progress'] = [i + 1, dataset_length]\n",
    "                dump_output(config['output_dir'], model_dict, dataset, cur_dataset)\n",
    "            del cur_dataset\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "        del detection_model\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-ethernet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rng\n",
    "rng.seed(12345)\n",
    "\n",
    "# Fourier Transform of Images\n",
    "\n",
    "with open(\"config.json\") as config_file:\n",
    "    config = json.load(config_file)\n",
    "    for model_dict in config['object_detectors']:\n",
    "        if not model_dict['active']:\n",
    "            continue\n",
    "        \n",
    "        for dataset in config['datasets']:\n",
    "            if not dataset['active']:\n",
    "                continue\n",
    "            dataset_path = os.path.normpath(dataset['path'])\n",
    "            out_dir = os.path.join(os.path.join(\n",
    "                os.path.normpath(config['output_dir']),\n",
    "                model_dict['abr']))\n",
    "            if not os.path.exists(out_dir):\n",
    "                os.makedirs(out_dir)\n",
    "\n",
    "            file_name = dataset['short_name'] + \".json\"\n",
    "            out_path = os.path.join(out_dir, file_name)\n",
    "\n",
    "            print(out_path)\n",
    "            \n",
    "            with open(out_path) as output_file:\n",
    "                output_json = json.load(output_file)\n",
    "                dataset = output_json['dataset']\n",
    "                i=0\n",
    "                for image_dict in dataset['images']:\n",
    "                    detection_obj = image_dict['output']\n",
    "                    image_path = os.path.join(dataset_path, image_dict['path'])\n",
    "                    original_image = cv.imread(image_path,cv.IMREAD_GRAYSCALE)\n",
    "                    \n",
    "                    for bb_box in detection_obj['bounding_boxes']:                        \n",
    "                        bb_start_x = bb_box['x']\n",
    "                        bb_end_x = bb_start_x + bb_box['width']\n",
    "                        bb_start_y = bb_box['y']\n",
    "                        bb_end_y = bb_start_y + bb_box['height']      \n",
    "\n",
    "                        ratio = bb_box['width']/bb_box['height']      \n",
    "                        print(\"The ratio is {}\".format(ratio))\n",
    "\n",
    "#                       crop the image as startY:endY, startX:endX \n",
    "                        bb_image = original_image[bb_start_y:bb_end_y, bb_start_x:bb_end_x]\n",
    "    \n",
    "                        try:\n",
    "                            fourier = np.fft.fft2(bb_image)\n",
    "                            fourier_shift = np.fft.fftshift(fourier)\n",
    "                            magnitude_spectrum = 20*np.log(np.abs(fourier_shift))\n",
    "                            magnitude_spectrum = np.asarray(magnitude_spectrum, dtype=np.uint8)\n",
    "    #                         axis-1, we want to concatenate them horizontally \n",
    "                            bb_img_and_magnitude = np.concatenate((bb_image, magnitude_spectrum), axis=0)\n",
    "        \n",
    "                        except:\n",
    "                            print(\"Unable to obtain fourier transform for {} \".format(image_dict['path']))\n",
    "\n",
    "                        ## Fourier Transform\n",
    "#                         f = cv.dft(np.float32(bb_image), flags=cv.DFT_COMPLEX_OUTPUT)\n",
    "#                         f_shift = np.fft.fftshift(f)\n",
    "#                         f_complex = f_shift[:,:,0] + 1j*f_shift[:,:,1]\n",
    "#                         f_abs = np.abs(f_complex) + 1 # lie between 1 and 1e6\n",
    "#                         f_bounded = 20 * np.log(f_abs)\n",
    "#                         f_img = 255 * f_bounded / np.max(f_bounded)\n",
    "#                         f_img = f_img.astype(np.uint8)\n",
    "#                         bb_img_and_f_img = np.concatenate((bb_image, f_img), axis=1)\n",
    "\n",
    "                        ## Histogram\n",
    "                        histogram = cv.calcHist([bb_image], [0], None, [256], [0, 256])\n",
    "\n",
    "\n",
    "#                         # plot the histogram\n",
    "                        plt.figure()\n",
    "                        plt.title(\"Grayscale Histogram\")\n",
    "                        plt.xlabel(\"Bins\")\n",
    "                        plt.ylabel(\"# of Pixels\")\n",
    "                        plt.plot(histogram)\n",
    "#                         plt.xlim([0, 256])\n",
    "                        \n",
    "                        imagepaths = image_dict['path'].split(\"/\")\n",
    "                        pltname = imagepaths.pop()+str(i)\n",
    "                        plt.savefig('_bird_detector_output/plots/{}.png'.format(pltname))\n",
    "                        i += 1\n",
    "#                         plt.show()\n",
    "\n",
    "                        threshold = 80\n",
    "                        im = cv.imread(image_path)\n",
    "                        cropped_im = im[bb_start_y:bb_end_y, bb_start_x:bb_end_x]\n",
    "          \n",
    "                        try:\n",
    "                            imgray = cv.cvtColor(cropped_im, cv.COLOR_BGR2GRAY)\n",
    "                            ret, thresh = cv.threshold(imgray, threshold, threshold*2, 0)\n",
    "                        except:\n",
    "                            print(\"Unable to obtain fourier transform for {} \".format(image_dict['path']))                        \n",
    "\n",
    "#                         # Detect edges using Canny\n",
    "#                         canny_output = cv.Canny(imgray, 100, 200)\n",
    "\n",
    "#                         contours, hierarchy = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#                         drawing = np.zeros((canny_output.shape[0], canny_output.shape[1], 3), dtype=np.uint8)\n",
    "#                         for i in range(len(contours)):\n",
    "#                             color = (rng.randint(0,256), rng.randint(0,256), rng.randint(0,256))\n",
    "#                             cv.drawContours(drawing, contours, i, color, 2, cv.LINE_8, hierarchy, 0)\n",
    "#                         # Show in a window\n",
    "#                         cv.imshow('Contours', drawing)\n",
    "\n",
    "                        cv.imwrite('_bird_detector_output/output_images/{}.png'.format(pltname),bb_img_and_magnitude)\n",
    "\n",
    "                        cv.imshow(\"Cropped Image\",bb_img_and_magnitude)\n",
    "                    cv.waitKey(0)\n",
    "                cv.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "increased-township",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-37-85e4c6b1fc2d>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-37-85e4c6b1fc2d>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    x = [[1. 2.],[2.],[3.]]\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# function that filters vowels\n",
    "def fun(variable):\n",
    "    letters = ['16', 'e', 'i', 'o', 'u']\n",
    "    print(letters)\n",
    "    if (variable in letters):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "  \n",
    "  \n",
    "# sequence\n",
    "sequence = ['16', 'e', 'e', 'j', 'k', 's', 'p', 'r']\n",
    "x = [[1. 2.],[2.],[3.]]\n",
    "y = [1. 2.]\n",
    "\n",
    "fasd = x.index(y)\n",
    "print(fasd)\n",
    "\n",
    "# using filter function\n",
    "filtered = filter(fun, sequence)\n",
    "  \n",
    "print('The filtered letters are:')\n",
    "print(list(filtered))\n",
    "# for s in filtered:\n",
    "#     print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "boolean-agriculture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "from cv2 import matchTemplate as cv2m\n",
    "\n",
    "def search_sequence_cv2(arr,seq):\n",
    "    \"\"\" Find sequence in an array using cv2.\n",
    "    \"\"\"\n",
    "\n",
    "    # Run a template match with input sequence as the template across\n",
    "    # the entire length of the input array and get scores.\n",
    "    S = cv2m(arr.astype('uint8'),seq.astype('uint8'),cv.TM_SQDIFF)\n",
    "\n",
    "    # Now, with floating point array cases, the matching scores might not be \n",
    "    # exactly zeros, but would be very small numbers as compared to others.\n",
    "    # So, for that use a very small to be used to threshold the scorees \n",
    "    # against and decide for matches.\n",
    "    thresh = 1e-5 # Would depend on elements in seq. So, be careful setting this.\n",
    "\n",
    "    # Find the matching indices\n",
    "    idx = np.where(S.ravel() < thresh)[0]\n",
    "\n",
    "    # Get the range of those indices as final output\n",
    "    if len(idx)>0:\n",
    "        return np.unique((idx[:,None] + np.arange(seq.size)).ravel())\n",
    "    else:\n",
    "        return []         # No match found\n",
    "\n",
    "arr = [[0.,15.,0.9745249,0.3137784,0.11997497,0.6873512,0.89939463],[0.,0.,0.,0.,0.,0.,0.]]\n",
    "seq = [0.,15.,0.9745249,0.3137784,0.11997497,0.6873512,0.89939463]\n",
    "# arr = [[1, 2, 0, 0],[3,4]]\n",
    "# seq = [3,4]\n",
    "\n",
    "fasd = arr.index(seq)\n",
    "print(fasd)\n",
    "\n",
    "# search_sequence_cv2(arr,seq)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-affiliate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Background subtraction method\n",
    "  \n",
    "# capture frames from a camera \n",
    "# img = cv.imread(\"Users/saravana/Documents/Work/Projects/Bird_Detection/output_images/bird_2.png\");\n",
    "\n",
    "\n",
    "# sharp_img = cv.createBackgroundSubtractorMOG2().apply(img)\n",
    "# # sharp_img = cv.bgsegm.createBackgroundSubtractorMOG().apply(img)\n",
    "# cv.imwrite('image2.png', sharp_img)\n",
    "\n",
    "\n",
    "# Parameters\n",
    "blur = 21\n",
    "canny_low = 15\n",
    "canny_high = 150\n",
    "min_area = 0.0005\n",
    "max_area = 0.95\n",
    "dilate_iter = 10\n",
    "erode_iter = 10\n",
    "mask_color = (108.0,0.0,0.0)\n",
    "\n",
    "# initialize video from the webcam\n",
    "video = cv.VideoCapture(0)\n",
    "# video = cv.VideoCapture(\"/Users/saravana/Documents/Photos/video.mp4\")\n",
    "        \n",
    "        \n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if ret == True:\n",
    "        # Convert image to grayscale       \n",
    "        image_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Apply Canny Edge Dection\n",
    "        edges = cv.Canny(image_gray, canny_low, canny_high)\n",
    "        edges = cv.dilate(edges, None)\n",
    "        edges = cv.erode(edges, None)\n",
    "        \n",
    "        # get the contours and their areas\n",
    "        contour_info = [(c, cv.contourArea(c),) for c in cv.findContours(edges, cv.RETR_LIST, cv.CHAIN_APPROX_NONE)[0]]\n",
    "        # Get the area of the image as a comparison\n",
    "        image_area = frame.shape[0] * frame.shape[1]  \n",
    "        \n",
    "        # calculate max and min areas in terms of pixels\n",
    "        max_area = max_area * image_area\n",
    "        min_area = min_area * image_area\n",
    "\n",
    "\n",
    "        # Set up mask with a matrix of 0's\n",
    "        mask = np.zeros(edges.shape, dtype = np.uint8)\n",
    "        # Go through and find relevant contours and apply to mask\n",
    "        for contour in contour_info:\n",
    "            # Instead of worrying about all the smaller contours, if the area is smaller than the min, the loop will break\n",
    "            if contour[1] > min_area and contour[1] < max_area:\n",
    "                # Add contour to mask\n",
    "                print(\"value\",contour[1])\n",
    "                mask = cv.fillConvexPoly(mask, contour[0], (255))\n",
    "       \n",
    "        # use dilate, erode, and blur to smooth out the mask\n",
    "        mask = cv.dilate(mask, None, iterations=dilate_iter)\n",
    "        mask = cv.erode(mask, None, iterations=erode_iter)\n",
    "        mask = cv.GaussianBlur(mask, (blur, blur), 0)\n",
    "                \n",
    "        # Ensures data types match up\n",
    "        mask_stack = np.dstack([mask]*3)\n",
    "        mask_stack = mask_stack.astype('float32') / 255.0           \n",
    "        frame = frame.astype('float32') / 255.0\n",
    "\n",
    "\n",
    "        # Blend the image and the mask\n",
    "        masked = (mask_stack * frame) + ((1-mask_stack) * mask_color)\n",
    "        masked = (masked * 255).astype('uint8')\n",
    "\n",
    "        cv.imshow(\"Foreground\", masked)\n",
    "        cv.imshow(\"Frame\",frame)\n",
    "        cv.imshow(\"edges\",edges)\n",
    "\n",
    "\n",
    "        # Use the q button to quit the operation\n",
    "        if cv.waitKey(60) & 0xff == ord('q'):\n",
    "            print(\"Q pressed\")\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contour detection method\n",
    "import argparse\n",
    "import random as rng\n",
    "rng.seed(12345)\n",
    "\n",
    "im = cv.imread('/Volumes/My-Passport/Dataset/CUB_200_2011/CUB_200_2011/images/001.Black_footed_Albatross/Black_Footed_Albatross_0001_796111.jpg')\n",
    "imgray = cv.cvtColor(im, cv.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv.threshold(imgray, 127, 255, 0)\n",
    "\n",
    "# Detect edges using Canny\n",
    "canny_output = cv.Canny(imgray, 100, 200)\n",
    "\n",
    "contours, hierarchy = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "drawing = np.zeros((canny_output.shape[0], canny_output.shape[1], 3), dtype=np.uint8)\n",
    "for i in range(len(contours)):\n",
    "    color = (rng.randint(0,256), rng.randint(0,256), rng.randint(0,256))\n",
    "    cv.drawContours(drawing, contours, i, color, 2, cv.LINE_8, hierarchy, 0)\n",
    "# Show in a window\n",
    "cv.imshow('Contours', drawing)\n",
    "cv.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-disclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Matching of Images\n",
    "\n",
    "# 1. Brute-Force Matching with ORB Descriptors\n",
    "\n",
    "img1 = cv.imread(\"/Users/saravana/Documents/Work/Projects/Bird_Detection/output_images/bird_2.png\",cv.IMREAD_GRAYSCALE)\n",
    "img2 = cv.imread(\"/Users/saravana/Documents/Work/Projects/Bird_Detection/output_images/bird_6.png\",cv.IMREAD_GRAYSCALE)\n",
    "# img1 = cv.imread(\"/Volumes/My-Passport/Dataset/CUB_200_2011/CUB_200_2011/images/001.Black_footed_Albatross/Black_Footed_Albatross_0001_796111.jpg\",cv.IMREAD_GRAYSCALE)\n",
    "# img2 = cv.imread(\"/Volumes/My-Passport/Dataset/CUB_200_2011/CUB_200_2011/images/001.Black_footed_Albatross/Black_Footed_Albatross_0002_55.jpg\",cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "# Initiate ORB detector\n",
    "orb = cv.ORB_create()\n",
    "\n",
    "# find the keypoints and descriptors with ORB\n",
    "kp1, des1 = orb.detectAndCompute(img1,None)\n",
    "kp2, des2 = orb.detectAndCompute(img2,None)\n",
    "\n",
    "# print(\"The description of img1 {} and img2 {}\".format(des1,des2))\n",
    "\n",
    "# create BFMatcher object\n",
    "bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "# Match descriptors.\n",
    "matches = bf.match(des1,des2)\n",
    "\n",
    "# Sort them in the order of their distance.\n",
    "matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "# Draw first 10 matches.\n",
    "img3 = cv.drawMatches(img1,kp1,img2,kp2,matches[:10],None,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "plt.figure(figsize=(15,15)),plt.imshow(img3),plt.show()\n",
    "\n",
    "plt.savefig('/Users/saravana/Documents/Work/Projects/Bird_Detection/_bird_detector_output/brute_force_matching.png'.format(pltname))\n",
    "\n",
    "## Histogram\n",
    "# histogram = cv.calcHist([img1], [0], None, [256], [0, 256])\n",
    "\n",
    "\n",
    "# # plot the histogram\n",
    "# plt.figure(figsize=(15,15))\n",
    "# plt.title(\"Grayscale Histogram\")\n",
    "# plt.xlabel(\"Bins\")\n",
    "# plt.ylabel(\"# of Pixels\")\n",
    "# plt.plot(histogram)\n",
    "# plt.xlim([0, 256])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Brute-Force Matching with SIFT Descriptors and Ratio Test\n",
    "\n",
    "# img1 = cv.imread(\"/Users/saravana/Documents/Work/Projects/Bird_Detection/output_images/bird_2.png\",cv.IMREAD_GRAYSCALE)\n",
    "# img2 = cv.imread(\"/Users/saravana/Documents/Work/Projects/Bird_Detection/output_images/bird_6.png\",cv.IMREAD_GRAYSCALE)\n",
    "img1 = cv.imread(\"/Volumes/My-Passport/Dataset/CUB_200_2011/CUB_200_2011/images/001.Black_footed_Albatross/Black_Footed_Albatross_0001_796111.jpg\",cv.IMREAD_GRAYSCALE)\n",
    "img2 = cv.imread(\"/Volumes/My-Passport/Dataset/CUB_200_2011/CUB_200_2011/images/001.Black_footed_Albatross/Black_Footed_Albatross_0002_55.jpg\",cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Initiate SIFT detector\n",
    "sift = cv.SIFT_create()\n",
    "# find the keypoints and descriptors with SIFT\n",
    "kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "\n",
    "# BFMatcher with default params\n",
    "bf = cv.BFMatcher()\n",
    "matches = bf.knnMatch(des1,des2,k=2)\n",
    "\n",
    "# Apply ratio test\n",
    "good = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.75*n.distance:\n",
    "        good.append([m])\n",
    "        \n",
    "# cv.drawMatchesKnn expects list of lists as matches.\n",
    "img3 = cv.drawMatchesKnn(img1,kp1,img2,kp2,good,None,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "plt.figure(figsize=(15,15)),plt.imshow(img3),plt.show()\n",
    "plt.savefig('/Users/saravana/Documents/Work/Projects/Bird_Detection/_bird_detector_output/brute_force_SIFT_matching.png'.format(pltname))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-finland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. FLANN based Matcher; FLANN-Fast Library for Approximate Nearest Neighbors\n",
    "\n",
    "# img1 = cv.imread(\"/Users/saravana/Documents/Work/Projects/Bird_Detection/output_images/bird_2.png\",cv.IMREAD_GRAYSCALE)\n",
    "# img2 = cv.imread(\"/Users/saravana/Documents/Work/Projects/Bird_Detection/output_images/bird_6.png\",cv.IMREAD_GRAYSCALE)\n",
    "img1 = cv.imread(\"/Volumes/My-Passport/Dataset/CUB_200_2011/CUB_200_2011/images/001.Black_footed_Albatross/Black_Footed_Albatross_0001_796111.jpg\",cv.IMREAD_GRAYSCALE)\n",
    "# img2 = cv.imread(\"/Volumes/My-Passport/Dataset/CUB_200_2011/CUB_200_2011/images/001.Black_footed_Albatross/Black_Footed_Albatross_0002_55.jpg\",cv.IMREAD_GRAYSCALE)\n",
    "img2 = cv.imread(\"/Volumes/My-Passport/Dataset/CUB_200_2011/CUB_200_2011/images/002.Laysan_Albatross/Laysan_Albatross_0003_1033.jpg\",cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Initiate SIFT detector\n",
    "sift = cv.SIFT_create()\n",
    "\n",
    "# find the keypoints and descriptors with SIFT\n",
    "kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "\n",
    "# FLANN parameters\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks=50)   # or pass empty dictionary\n",
    "\n",
    "flann = cv.FlannBasedMatcher(index_params,search_params)\n",
    "matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "# Need to draw only good matches, so create a mask\n",
    "matchesMask = [[0,0] for i in range(len(matches))]\n",
    "\n",
    "# ratio test as per Lowe's paper\n",
    "for i,(m,n) in enumerate(matches):\n",
    "    if m.distance < 0.75*n.distance:\n",
    "        matchesMask[i]=[1,0]\n",
    "\n",
    "        \n",
    "draw_params = dict(matchColor = (0,255,0),\n",
    "                   singlePointColor = (255,0,0),\n",
    "                   matchesMask = matchesMask,\n",
    "                   flags = cv.DrawMatchesFlags_DEFAULT)\n",
    "\n",
    "img3 = cv.drawMatchesKnn(img1,kp1,img2,kp2,matches,None,**draw_params)\n",
    "plt.figure(figsize=(15,15)),plt.imshow(img3,),plt.show()\n",
    "plt.savefig('/Users/saravana/Documents/Work/Projects/Bird_Detection/_bird_detector_output/FLANN_Based_matching.png'.format(pltname))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-frontier",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_path)\n",
    "trainval_jpeg = os.path.join(dataset_path,\"trainval/JPEGImages\")\n",
    "trainval_annotations = os.path.join(dataset_path,\"trainval/Annotations\")\n",
    "\n",
    "trainval_data = []\n",
    "with open(trainval_path) as f:\n",
    "    trainval_data = [line.split(None, 1)[0] for line in f]\n",
    "\n",
    "if not os.path.exists(trainval_jpeg) and not os.path.exists(trainval_annotations):\n",
    "    os.makedirs(trainval_jpeg)\n",
    "    os.makedirs(trainval_annotations)\n",
    "    \n",
    "if len(os.listdir(trainval_jpeg)) == 0 and len(os.listdir(trainval_annotations)) == 0:\n",
    "    jpegs = os.path.join(dataset_path,\"JPEGImages\")\n",
    "    annotations = os.path.join(dataset_path,\"Annotations\")\n",
    "    trainval_path = os.path.join(dataset_path,\"ImageSets/Layout/trainval.txt\")\n",
    "    img_annotations = os.listdir(annotations)\n",
    "    \n",
    "    for i,each in enumerate(os.listdir(jpegs)):\n",
    "        print(i)\n",
    "        filename_no_ext = \".\".join(each.split(\".\")[:-1])\n",
    "        for item in trainval_data:\n",
    "            if item == filename_no_ext:\n",
    "                src_jpeg_path = os.path.join(jpegs,each)\n",
    "                src_annotation_path = os.path.join(annotations,img_annotations[i])\n",
    "                dst_jpeg_path = os.path.join(trainval_jpeg,each)\n",
    "                dst_annotation_path = os.path.join(trainval_annotations,img_annotations[i])\n",
    "                \n",
    "                shutil.copyfile(src_jpeg_path, dst_jpeg_path)\n",
    "                shutil.copyfile(src_annotation_path, dst_annotation_path)\n",
    "                print(item)\n",
    "        \n",
    "print(len(trainval_data))\n",
    "print(\"Training Jpeg\")\n",
    "print(len(os.listdir(trainval_jpeg)))\n",
    "print(\"Training Annotations\")\n",
    "print(len(os.listdir(trainval_annotations)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-diving",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "data_set_path = \"/Volumes/My-Passport/Dataset/CUB_200_2011/CUB_200_2011\"\n",
    "images_text_path = os.path.join(data_set_path,\"images.txt\")\n",
    "\n",
    "data = {}\n",
    "\n",
    "dataset_obj = {}\n",
    "dataset_obj['initialized'] = True\n",
    "dataset_obj['classes'] = [\"person\", \"bird\", \"cat\", \"cow\", \"dog\", \"horse\", \"sheep\", \"aeroplane\", \"bicycle\", \"boat\", \"bus\", \"car\", \"motorbike\", \"train\", \"bottle\", \"chair\", \"dining table\", \"potted plant\", \"sofa\", \"tv/monitor\"]\n",
    "\n",
    "images = []\n",
    "\n",
    "bounding_box_path = os.path.join(data_set_path,\"bounding_boxes.txt\")\n",
    "with open(bounding_box_path) as bb_path:\n",
    "    bb_lines = bb_path.readlines()\n",
    "    bb_columns = []\n",
    "\n",
    "    for bb_line in bb_lines:\n",
    "        bb_line = bb_line.strip()\n",
    "        bb_array = [bb_item.strip() for bb_item in bb_line.split(' ')]\n",
    "        bb_columns.append(bb_array)\n",
    "    \n",
    "\n",
    "with open(images_text_path) as f:\n",
    "    lines = f.readlines()\n",
    "    columns = [] # To store column names\n",
    "\n",
    "    i = 1\n",
    "    for line in lines:\n",
    "        line = line.strip() # remove leading/trailing white spaces\n",
    "        image_list_array = [item.strip() for item in line.split(' ')]\n",
    "        columns.append(image_list_array)\n",
    "    \n",
    "    for index,item in enumerate(columns):\n",
    "        coco_image_path = item[1]\n",
    "        image_obj = {}\n",
    "        image_obj['path'] = \"images/\"+coco_image_path\n",
    "        \n",
    "        image = Image.open(os.path.join(data_set_path,image_obj['path']))\n",
    "        width, height = image.size\n",
    "        image_obj['width'] = float(width)\n",
    "        image_obj['height'] = float(width)\n",
    "\n",
    "        \n",
    "        bounding_boxes = []\n",
    "        if item[0] == bb_columns[index][0]:\n",
    "            bounding_box_obj = {}\n",
    "            bounding_box_obj['x'] = bb_columns[index][1]\n",
    "            bounding_box_obj['y'] = bb_columns[index][2]\n",
    "            bounding_box_obj['width'] = bb_columns[index][3]\n",
    "            bounding_box_obj['height'] = bb_columns[index][4]\n",
    "            bounding_boxes.append(bounding_box_obj)\n",
    "        \n",
    "        image_obj['bounding_boxes'] = bounding_boxes\n",
    "        images.append(image_obj)\n",
    "    \n",
    "\n",
    "dataset_obj['images'] = images\n",
    "data['dataset'] = dataset_obj\n",
    "\n",
    "print(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-advancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.nontf_util import *\n",
    "\n",
    "with open(\"config.json\") as config_file:\n",
    "    config = json.load(config_file)\n",
    "    for model_dict in config['object_detectors']:\n",
    "        if not model_dict['active']:\n",
    "            continue\n",
    "        print(\"Model dict {}\".format(model_dict['name']))\n",
    "        detection_model = load_model(model_dict['name'])\n",
    "        print(\"Model {} loaded, start testing.\".format(model_dict['abr']))\n",
    "        for dataset in config['datasets']:\n",
    "            if not dataset['active']:\n",
    "                continue\n",
    "            dataset_path = os.path.normpath(dataset['path'])\n",
    "            out_dir = os.path.join(os.path.join(\n",
    "                os.path.normpath(config['output_dir']),\n",
    "                model_dict['abr']))\n",
    "            if not os.path.exists(out_dir):\n",
    "                os.makedirs(out_dir)\n",
    "\n",
    "            file_name = dataset['short_name'] + \".json\"\n",
    "            out_path = os.path.join(out_dir, file_name)\n",
    "            if not sys.path[0] == dataset_path:\n",
    "                sys.path.insert(0, dataset_path)\n",
    "\n",
    "            print(sys.path)\n",
    "            print(out_path)\n",
    "            \n",
    "            dataloader = load_caltech_cub(dataset_path,dataset,model_dict)\n",
    "            cur_dataset = dataloader['dataset']\n",
    "            \n",
    "            print(\"Start testing for dataset {}.\".format(dataset['short_name']))\n",
    "            dataset_length = len(cur_dataset['images'])\n",
    "            print()\n",
    "            progress, cur_dataset = checkprogress(out_path, cur_dataset)\n",
    "            for i, image in enumerate(cur_dataset['images']):\n",
    "                print_progress_bar(i + 1, dataset_length, prefix=\"{}/{}\".format(i + 1, dataset_length))\n",
    "                print(\"The progress is is {}\".format(progress))\n",
    "                if progress > i:\n",
    "                    continue\n",
    "                abspath = os.path.join(dataset_path, image['path'])\n",
    "                                \n",
    "                try:\n",
    "                    output = run_inference(detection_model, abspath)\n",
    "                    image['output'] = output_to_abs(image, output)\n",
    "                    show_inference(detection_model, abspath)\n",
    "                except:\n",
    "                    print(\"The exception is {}\".format(e))\n",
    "                    print(\"Problem with image_data {} from dataset {}\".format(image['path'], dataset['short_name']))\n",
    "                    \n",
    "                dataset['progress'] = [i + 1, dataset_length]\n",
    "                dump_output(config['output_dir'], model_dict, dataset, cur_dataset)\n",
    "            del cur_dataset\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "        del detection_model\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cv2.__version__\n",
    "\n",
    "image_path = \"/Volumes/My-Passport/Dataset/CUB_200_2011/CUB_200_2011/images/001.Black_footed_Albatross/Black_Footed_Albatross_0001_796111.jpg\"\n",
    "original_image = cv2.imread(image_path)\n",
    "cv2.imshow(\"original Image\",original_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-girlfriend",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
